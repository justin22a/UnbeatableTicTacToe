{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8adab345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation with Linear SVM: 98.33%\n",
      "test split accuracy using Linear SVM: 96.88%\n",
      "[[ 61   6]\n",
      " [  0 125]]\n"
     ]
    }
   ],
   "source": [
    "#svm on final\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "#load data\n",
    "data = np.loadtxt('datasets/tictac_final.txt')\n",
    "input_data = data[:,:9]\n",
    "output_data = data[:,9].ravel()  # Convert to 1D array for compatibility\n",
    "classifier = svm.SVC(kernel='linear')\n",
    "#cross validation (randomize it)\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "cross_val_accuracies = cross_val_score(classifier, input_data, output_data, cv=kf)\n",
    "mean_accuracy = np.mean(cross_val_accuracies)\n",
    "print(f\"Cross validation with Linear SVM: {mean_accuracy * 100:.2f}%\")\n",
    "#train\n",
    "x_train, x_test, y_train, y_test = train_test_split(input_data, output_data, test_size=0.2, random_state=42)\n",
    "classifier.fit(x_train, y_train)\n",
    "y_pred = classifier.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "#accuracy and confusion matrix\n",
    "print(f\"test split accuracy using Linear SVM: {accuracy * 100:.2f}%\")\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1d12ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation with K-Nearest Neighbors: 99.89%\n",
      "test split accuracy using K-Nearest Neighbors: 99.48%\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 66   1]\n",
      " [  0 125]]\n"
     ]
    }
   ],
   "source": [
    "#k neighbors on final\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "# Load the data\n",
    "data = np.loadtxt('datasets/tictac_final.txt')\n",
    "input_data = data[:,:9]\n",
    "output_data = data[:,9].ravel() \n",
    "# Initialize K-Nearest Neighbors classifier\n",
    "classifier = KNeighborsClassifier()\n",
    "#cross validation with randomization\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "cross_val_accuracies = cross_val_score(classifier, input_data, output_data, cv=kf)\n",
    "mean_accuracy = np.mean(cross_val_accuracies)\n",
    "print(f\"Cross validation with K-Nearest Neighbors: {mean_accuracy * 100:.2f}%\")\n",
    "#split\n",
    "x_train, x_test, y_train, y_test = train_test_split(input_data, output_data, test_size=0.2, random_state=42)\n",
    "classifier.fit(x_train, y_train)\n",
    "y_pred = classifier.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "#accuracy and confusion matrix\n",
    "print(f\"test split accuracy using K-Nearest Neighbors: {accuracy * 100:.2f}%\")\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45cafc63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation with MLP: 98.33%\n",
      "test split accuracy using MLP: 97.40%\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 62   5]\n",
      " [  0 125]]\n"
     ]
    }
   ],
   "source": [
    "#mlp on final\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "#load the data with path\n",
    "data = np.loadtxt('datasets/tictac_final.txt')\n",
    "input_data = data[:,:9]\n",
    "output_data = data[:,9].ravel()\n",
    "#choose the type of classifier\n",
    "classifier = MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000, activation='relu', random_state=42)\n",
    "#cross validation\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "cross_val_accuracies = cross_val_score(classifier, input_data, output_data, cv=kf)\n",
    "mean_accuracy = np.mean(cross_val_accuracies)\n",
    "#print the accuracy of the cross validation\n",
    "print(f\"cross validation with MLP: {mean_accuracy * 100:.2f}%\")\n",
    "#train\n",
    "x_train, x_test, y_train, y_test = train_test_split(input_data, output_data, test_size=0.2, random_state=42)\n",
    "classifier.fit(x_train, y_train)\n",
    "y_pred = classifier.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "#accuracy of model and confusion matrix\n",
    "print(f\"test split accuracy using MLP: {accuracy * 100:.2f}%\")\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d615a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Load the data\n",
    "data = np.loadtxt('datasets/tictac_single.txt')\n",
    "input_data = data[:,:9]\n",
    "output_data = data[:,9].ravel()\n",
    "scaler = StandardScaler()\n",
    "input_data = scaler.fit_transform(input_data)\n",
    "#choose classifier and use cross validation with randomization\n",
    "classifier = SVC(kernel='linear')\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cross_val_accuracies = cross_val_score(classifier, input_data, output_data, cv=kf)\n",
    "#find accuracy and print it\n",
    "mean_accuracy = np.mean(cross_val_accuracies)\n",
    "print(f\"Cross validation with Linear SVM: {mean_accuracy * 100:.2f}%\")\n",
    "#train the data\n",
    "x_train, x_test, y_train, y_test = train_test_split(input_data, output_data, test_size=0.2, random_state=42)\n",
    "classifier.fit(x_train, y_train)\n",
    "y_pred = classifier.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "#accuracy and confusion matrix\n",
    "print(f\"Test split accuracy using Linear SVM: {accuracy * 100:.2f}%\")\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e03ba03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Load the data\n",
    "data = np.loadtxt('datasets/tictac_single.txt')\n",
    "input_data = data[:, :9]\n",
    "output_data = data[:, 9].ravel()\n",
    "scaler = StandardScaler()\n",
    "input_data = scaler.fit_transform(input_data)\n",
    "best_k = 1\n",
    "best_score = 0\n",
    "#cross validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=23)\n",
    "#tried a bunch of different values but found one that worked\n",
    "for k in range(7,8):  # try values of k from 1 to 30\n",
    "    classifier = KNeighborsClassifier(n_neighbors=k, weights='distance')  # using distance weights\n",
    "    cross_val_accuracies = cross_val_score(classifier, input_data, output_data, cv=kf)\n",
    "    mean_accuracy = np.mean(cross_val_accuracies)\n",
    "    if mean_accuracy > best_score:\n",
    "        best_k = k\n",
    "        best_score = mean_accuracy\n",
    "#print the accuracies with the best k\n",
    "print(f\"Best number of neighbors: {best_k}\")\n",
    "print(f\"Cross validation accuracy with best KNN: {best_score * 100:.2f}%\")\n",
    "#train the data\n",
    "classifier = KNeighborsClassifier(n_neighbors=best_k, weights='distance')\n",
    "x_train, x_test, y_train, y_test = train_test_split(input_data, output_data, test_size=0.2, random_state=23)\n",
    "classifier.fit(x_train, y_train)\n",
    "y_pred = classifier.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "#print accuracy and confusion matrix\n",
    "print(f\"Test split accuracy using best KNN: {accuracy * 100:.2f}%\")\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d242084",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Load the data\n",
    "data = np.loadtxt('datasets/tictac_single.txt')\n",
    "# Separate the data into input and output\n",
    "input_data = data[:,:9]\n",
    "output_data = data[:,9].ravel()\n",
    "# Standardize the data, this is particularly important for neural networks\n",
    "scaler = StandardScaler()\n",
    "input_data = scaler.fit_transform(input_data)\n",
    "# Initialize MLP classifier\n",
    "classifier = MLPClassifier(hidden_layer_sizes=(50, 50), max_iter=100, random_state=42, activation='relu', solver='adam')\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cross_val_accuracies = cross_val_score(classifier, input_data, output_data, cv=kf)\n",
    "mean_accuracy = np.mean(cross_val_accuracies)\n",
    "print(f\"Cross validation with MLP: {mean_accuracy * 100:.2f}%\")\n",
    "# Train the classifier on the train split and evaluate on test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(input_data, output_data, test_size=0.2, random_state=42)\n",
    "classifier.fit(x_train, y_train)\n",
    "y_pred = classifier.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test split accuracy using MLP: {accuracy * 100:.2f}%\")\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455595d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#split the data with multiple labels based on format of data\n",
    "def multi_label_confusion_matrix(y_true, y_pred):\n",
    "    num_labels = y_true.shape[1]\n",
    "    #confusion matrix\n",
    "    conf_matrix = np.zeros((num_labels, 2, 2))\n",
    "    #combinations\n",
    "    for i in range(num_labels):\n",
    "        #check if values in certain rows result to true\n",
    "        tp = np.sum((y_true[:, i] == 1) & (y_pred[:, i] == 1))\n",
    "        tn = np.sum((y_true[:, i] == 0) & (y_pred[:, i] == 0))\n",
    "        fp = np.sum((y_true[:, i] == 0) & (y_pred[:, i] == 1))\n",
    "        fn = np.sum((y_true[:, i] == 1) & (y_pred[:, i] == 0))\n",
    "        conf_matrix[i] = [[tp, fp], [fn, tn]]\n",
    "    return conf_matrix\n",
    "data = np.loadtxt('datasets/tictac_multi.txt')\n",
    "X = data[:,:9]\n",
    "y = data[:,9:]\n",
    "#scale the data\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "#split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=23)\n",
    "#cross validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "print(\"Linear regression: \")\n",
    "linear_models = [LinearRegression() for _ in range(9)]\n",
    "#initialize arrays for splitting of data\n",
    "predictions = []\n",
    "cross_val_accuracies_lr = []\n",
    "#iterate each linear model for this type of regression and data and add to initialized arrays\n",
    "for i, model in enumerate(linear_models):\n",
    "    acc = cross_val_score(model, X, y[:, i], cv=kf)\n",
    "    cross_val_accuracies_lr.append(np.mean(acc))\n",
    "    model.fit(X_train, y_train[:, i])\n",
    "    pred = model.predict(X_test)\n",
    "    predictions.append(pred)\n",
    "#check the score of corss validation\n",
    "mean_cross_val_accuracy_lr = np.mean(cross_val_accuracies_lr)\n",
    "#cross validation code\n",
    "print(f\"cross validation with Linear Regression: {mean_cross_val_accuracy_lr * 100:.2f}%\")\n",
    "predictions = np.array(predictions).T\n",
    "#round or clamp to 0 or 1 for each regression output\n",
    "predictions = (predictions == predictions.max(axis=1)[:, None]).astype(int)\n",
    "acc = accuracy_score(y_test, predictions)\n",
    "#show accuracy with linear regression\n",
    "print(f\"Accuracy using Linear Regression: {acc * 100:.2f}%\")\n",
    "print(\"Confusion Matrix for Linear Regression:\")\n",
    "print(multi_label_confusion_matrix(y_test, predictions))\n",
    "# KNN regression below\n",
    "print(\"\\nEvaluating kNN Regression...\")\n",
    "#i chose to use 15 neighbors here\n",
    "knn = KNeighborsRegressor(n_neighbors=15)\n",
    "cross_val_accuracies_knn = cross_val_score(knn, X, y, cv=kf)\n",
    "mean_cross_val_accuracy_knn = np.mean(cross_val_accuracies_knn)\n",
    "#show cross validation score with using KNN\n",
    "print(f\"Cross validation with kNN Regression: {mean_cross_val_accuracy_knn * 100:.2f}%\")\n",
    "#train the data\n",
    "knn.fit(X_train, y_train)\n",
    "knn_preds = knn.predict(X_test)\n",
    "knn_preds = (knn_preds == knn_preds.max(axis=1)[:, None]).astype(int)\n",
    "#show the accuracy with the KNN model\n",
    "acc = accuracy_score(y_test, knn_preds)\n",
    "print(f\"Accuracy using kNN Regression: {acc * 100:.2f}%\")\n",
    "print(\"Confusion Matrix for kNN Regression:\")\n",
    "print(multi_label_confusion_matrix(y_test, knn_preds))\n",
    "# MLP Regression\n",
    "print()\n",
    "print(\"MLP Below:\")\n",
    "#use mlp and layer it with a random state as well\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(100,), max_iter=10000, random_state=23)\n",
    "#cross validate with mlp\n",
    "cross_val_accuracies_mlp = cross_val_score(mlp, X, y, cv=kf)\n",
    "mean_cross_val_accuracy_mlp = np.mean(cross_val_accuracies_mlp)\n",
    "#show the accuracy of cross validation with mlp\n",
    "print(f\"Cross validation with MLP Regression: {mean_cross_val_accuracy_mlp * 100:.2f}%\")]\n",
    "#train the data\n",
    "mlp.fit(X_train, y_train)\n",
    "mlp_preds = mlp.predict(X_test)\n",
    "mlp_preds = (mlp_preds == mlp_preds.max(axis=1)[:, None]).astype(int)\n",
    "acc = accuracy_score(y_test, mlp_preds)\n",
    "#show the accuracy and confusion matrix\n",
    "print(f\"Accuracy using MLP Regression: {acc * 100:.2f}%\")\n",
    "print(\"Confusion Matrix for MLP Regression:\")\n",
    "print(multi_label_confusion_matrix(y_test, mlp_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7704c4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#currently trying tic tac toe against mlp regression\n",
    "# load and preprocess data\n",
    "data = np.loadtxt('datasets/tictac_multi.txt')\n",
    "X = data[:, :9]\n",
    "y = data[:, 9:]\n",
    "#scale the data\n",
    "scaler = StandardScaler().fit(X)\n",
    "#use mlp\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(100,), max_iter=10000).fit(scaler.transform(X), y)\n",
    "#define how the ML will make a move\n",
    "def ML_move(board):\n",
    "    #make prediction\n",
    "    preds = mlp.predict(scaler.transform([board]))\n",
    "    #make a move\n",
    "    move = np.argmax(preds)\n",
    "    #return the move value\n",
    "    while board[move] != 0:\n",
    "        preds[0][move] = -np.inf\n",
    "        move = np.argmax(preds)\n",
    "    return move\n",
    "#print the board\n",
    "def print_board(b):\n",
    "    chars = ['O', ' ', 'X']\n",
    "    for i in range(0, 9, 3):\n",
    "        #print for each row/col in the tic tac toe board\n",
    "        print(\"|\".join([chars[val+1] for val in b[i:i+3]]))\n",
    "#hardcoded to see which game state had a winner\n",
    "def check_winner(b):\n",
    "    wins = [(0,1,2), (3,4,5), (6,7,8), (0,3,6), (1,4,7), (2,5,8), (0,4,8), (2,4,6)]\n",
    "    #return the possibility of someone winning\n",
    "    return any(b[i] == b[j] == b[k] and b[i] != 0 for i, j, k in wins)\n",
    "#initalize the board\n",
    "board = np.zeros(9, dtype=int)\n",
    "#while true meaning we keep playing the game (didn't make it continuous)\n",
    "while True:\n",
    "    print_board(board)\n",
    "    move = int(input(\"Your move (1-9): \"))\n",
    "    move -=1\n",
    "    if board[move] == 0:\n",
    "        board[move] = 1\n",
    "        if check_winner(board):\n",
    "            print_board(board)\n",
    "            print(\"win\")\n",
    "            break\n",
    "        if 0 not in board:\n",
    "            print_board(board)\n",
    "            print(\"draw\")\n",
    "            break\n",
    "        board[ML_move(board)] = -1\n",
    "        if check_winner(board):\n",
    "            print_board(board)\n",
    "            print(\"loss\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73515e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extra Credit Linear Regression normal equations\n",
    "#https://www.educative.io/answers/a-deep-dive-into-linear-regression-3-way-implementation\n",
    "#I used the article above to try and learn more about it (not sure if i'm correct in this implementation)\n",
    "#I'm trying to use theta = (X^TX)^(-1)X^Ty\n",
    "import numpy as np\n",
    "#some X variable\n",
    "X = sudodata\n",
    "Y = sudodata\n",
    "\n",
    "#add bias\n",
    "xb = np.c_[np.ones((X.shape[0], 1)), X]\n",
    "    \n",
    "#theta??\n",
    "theta = np.linalg.pinv(xb.T.dot(xb)).dot(xb.T).dot(y) \n",
    "\n",
    "#theta would be the output?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd59a12b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
