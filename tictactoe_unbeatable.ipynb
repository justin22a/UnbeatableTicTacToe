{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8adab345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation with Linear SVM: 98.33%\n",
      "test split accuracy using Linear SVM: 96.88%\n",
      "[[ 61   6]\n",
      " [  0 125]]\n"
     ]
    }
   ],
   "source": [
    "#svm on final\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "#load data\n",
    "data = np.loadtxt('datasets/tictac_final.txt')\n",
    "input_data = data[:,:9]\n",
    "output_data = data[:,9].ravel()  # Convert to 1D array for compatibility\n",
    "classifier = svm.SVC(kernel='linear')\n",
    "#cross validation (randomize it)\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "cross_val_accuracies = cross_val_score(classifier, input_data, output_data, cv=kf)\n",
    "mean_accuracy = np.mean(cross_val_accuracies)\n",
    "print(f\"Cross validation with Linear SVM: {mean_accuracy * 100:.2f}%\")\n",
    "#train\n",
    "x_train, x_test, y_train, y_test = train_test_split(input_data, output_data, test_size=0.2, random_state=42)\n",
    "classifier.fit(x_train, y_train)\n",
    "y_pred = classifier.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "#accuracy and confusion matrix\n",
    "print(f\"test split accuracy using Linear SVM: {accuracy * 100:.2f}%\")\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1d12ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation with K-Nearest Neighbors: 99.89%\n",
      "test split accuracy using K-Nearest Neighbors: 99.48%\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 66   1]\n",
      " [  0 125]]\n"
     ]
    }
   ],
   "source": [
    "#k neighbors on final\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "# Load the data\n",
    "data = np.loadtxt('datasets/tictac_final.txt')\n",
    "input_data = data[:,:9]\n",
    "output_data = data[:,9].ravel() \n",
    "# Initialize K-Nearest Neighbors classifier\n",
    "classifier = KNeighborsClassifier()\n",
    "#cross validation with randomization\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "cross_val_accuracies = cross_val_score(classifier, input_data, output_data, cv=kf)\n",
    "mean_accuracy = np.mean(cross_val_accuracies)\n",
    "print(f\"Cross validation with K-Nearest Neighbors: {mean_accuracy * 100:.2f}%\")\n",
    "#split\n",
    "x_train, x_test, y_train, y_test = train_test_split(input_data, output_data, test_size=0.2, random_state=42)\n",
    "classifier.fit(x_train, y_train)\n",
    "y_pred = classifier.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "#accuracy and confusion matrix\n",
    "print(f\"test split accuracy using K-Nearest Neighbors: {accuracy * 100:.2f}%\")\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45cafc63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation with MLP: 98.33%\n",
      "test split accuracy using MLP: 97.40%\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 62   5]\n",
      " [  0 125]]\n"
     ]
    }
   ],
   "source": [
    "#mlp on final\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "#load the data with path\n",
    "data = np.loadtxt('datasets/tictac_final.txt')\n",
    "input_data = data[:,:9]\n",
    "output_data = data[:,9].ravel()\n",
    "#choose the type of classifier\n",
    "classifier = MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000, activation='relu', random_state=42)\n",
    "#cross validation\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "cross_val_accuracies = cross_val_score(classifier, input_data, output_data, cv=kf)\n",
    "mean_accuracy = np.mean(cross_val_accuracies)\n",
    "#print the accuracy of the cross validation\n",
    "print(f\"cross validation with MLP: {mean_accuracy * 100:.2f}%\")\n",
    "#train\n",
    "x_train, x_test, y_train, y_test = train_test_split(input_data, output_data, test_size=0.2, random_state=42)\n",
    "classifier.fit(x_train, y_train)\n",
    "y_pred = classifier.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "#accuracy of model and confusion matrix\n",
    "print(f\"test split accuracy using MLP: {accuracy * 100:.2f}%\")\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d615a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation with Linear SVM: 35.31%\n",
      "Test split accuracy using Linear SVM: 35.32%\n",
      "\n",
      "Confusion Matrix:\n",
      "[[323   0   0   0   0   0   0   0   0]\n",
      " [ 90  16  29   0  33   0   0   0   0]\n",
      " [112   0  43   0  32   0   0   0   0]\n",
      " [ 73   6  21   1  16   0   0   0   0]\n",
      " [122   0   0   0  80   0   0   0   0]\n",
      " [ 41   7  20   0   8   0   0   0   0]\n",
      " [ 55   8  20   2  14   0   0   0   0]\n",
      " [ 30   9   9   0   2   0   0   0   0]\n",
      " [ 56   5  19   0   9   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Load the data\n",
    "data = np.loadtxt('datasets/tictac_single.txt')\n",
    "input_data = data[:,:9]\n",
    "output_data = data[:,9].ravel()\n",
    "scaler = StandardScaler()\n",
    "input_data = scaler.fit_transform(input_data)\n",
    "#choose classifier and use cross validation with randomization\n",
    "classifier = SVC(kernel='linear')\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cross_val_accuracies = cross_val_score(classifier, input_data, output_data, cv=kf)\n",
    "#find accuracy and print it\n",
    "mean_accuracy = np.mean(cross_val_accuracies)\n",
    "print(f\"Cross validation with Linear SVM: {mean_accuracy * 100:.2f}%\")\n",
    "#train the data\n",
    "x_train, x_test, y_train, y_test = train_test_split(input_data, output_data, test_size=0.2, random_state=42)\n",
    "classifier.fit(x_train, y_train)\n",
    "y_pred = classifier.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "#accuracy and confusion matrix\n",
    "print(f\"Test split accuracy using Linear SVM: {accuracy * 100:.2f}%\")\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e03ba03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best number of neighbors: 7\n",
      "Cross validation accuracy with best KNN: 89.64%\n",
      "Test split accuracy using best KNN: 90.39%\n",
      "\n",
      "Confusion Matrix:\n",
      "[[303   4   5   1   6   0   2   1   0]\n",
      " [  4 153   3   0   2   1   0   1   3]\n",
      " [  4   3 171   2   2   2   1   0   1]\n",
      " [  1   4   1  76   7   1   5   0   4]\n",
      " [  7   8   2   0 202   0   0   0   0]\n",
      " [  0   2   0   1   0  53   0   0   1]\n",
      " [  5   1   1   6   2   0  97   3   1]\n",
      " [  2   0   0   1   0   0   0  42   1]\n",
      " [  2   1   1   2   4   0   0   1  88]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Load the data\n",
    "data = np.loadtxt('datasets/tictac_single.txt')\n",
    "input_data = data[:, :9]\n",
    "output_data = data[:, 9].ravel()\n",
    "scaler = StandardScaler()\n",
    "input_data = scaler.fit_transform(input_data)\n",
    "best_k = 1\n",
    "best_score = 0\n",
    "#cross validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=23)\n",
    "#tried a bunch of different values but found one that worked\n",
    "for k in range(7,8):  # try values of k from 1 to 30\n",
    "    classifier = KNeighborsClassifier(n_neighbors=k, weights='distance')  # using distance weights\n",
    "    cross_val_accuracies = cross_val_score(classifier, input_data, output_data, cv=kf)\n",
    "    mean_accuracy = np.mean(cross_val_accuracies)\n",
    "    if mean_accuracy > best_score:\n",
    "        best_k = k\n",
    "        best_score = mean_accuracy\n",
    "#print the accuracies with the best k\n",
    "print(f\"Best number of neighbors: {best_k}\")\n",
    "print(f\"Cross validation accuracy with best KNN: {best_score * 100:.2f}%\")\n",
    "#train the data\n",
    "classifier = KNeighborsClassifier(n_neighbors=best_k, weights='distance')\n",
    "x_train, x_test, y_train, y_test = train_test_split(input_data, output_data, test_size=0.2, random_state=23)\n",
    "classifier.fit(x_train, y_train)\n",
    "y_pred = classifier.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "#print accuracy and confusion matrix\n",
    "print(f\"Test split accuracy using best KNN: {accuracy * 100:.2f}%\")\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d242084",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/justinadam/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/justinadam/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/justinadam/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/justinadam/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/justinadam/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation with MLP: 86.25%\n",
      "Test split accuracy using MLP: 86.12%\n",
      "\n",
      "Confusion Matrix:\n",
      "[[284   3   4   4  13   1   6   4   4]\n",
      " [  7 139   8   0   2   3   3   1   5]\n",
      " [  8   5 158   4   5   0   2   2   3]\n",
      " [  1   2   3 101   3   2   3   1   1]\n",
      " [ 18   4   3   1 172   0   2   2   0]\n",
      " [  0   4   1   0   0  65   2   2   2]\n",
      " [  3   1   3   5   0   0  86   0   1]\n",
      " [  1   0   0   3   0   0   0  46   0]\n",
      " [  2   2   2   1   0   0   2   2  78]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/justinadam/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Load the data\n",
    "data = np.loadtxt('datasets/tictac_single.txt')\n",
    "# Separate the data into input and output\n",
    "input_data = data[:,:9]\n",
    "output_data = data[:,9].ravel()\n",
    "# Standardize the data, this is particularly important for neural networks\n",
    "scaler = StandardScaler()\n",
    "input_data = scaler.fit_transform(input_data)\n",
    "# Initialize MLP classifier\n",
    "classifier = MLPClassifier(hidden_layer_sizes=(50, 50), max_iter=100, random_state=42, activation='relu', solver='adam')\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cross_val_accuracies = cross_val_score(classifier, input_data, output_data, cv=kf)\n",
    "mean_accuracy = np.mean(cross_val_accuracies)\n",
    "print(f\"Cross validation with MLP: {mean_accuracy * 100:.2f}%\")\n",
    "# Train the classifier on the train split and evaluate on test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(input_data, output_data, test_size=0.2, random_state=42)\n",
    "classifier.fit(x_train, y_train)\n",
    "y_pred = classifier.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test split accuracy using MLP: {accuracy * 100:.2f}%\")\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "455595d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear regression: \n",
      "cross validation with Linear Regression: 0.15%\n",
      "Accuracy using Linear Regression: 13.81%\n",
      "Confusion Matrix for Linear Regression:\n",
      "[[[8.000e+00 5.500e+01]\n",
      "  [3.140e+02 9.340e+02]]\n",
      "\n",
      " [[0.000e+00 0.000e+00]\n",
      "  [2.130e+02 1.098e+03]]\n",
      "\n",
      " [[2.800e+01 9.900e+01]\n",
      "  [2.690e+02 9.150e+02]]\n",
      "\n",
      " [[0.000e+00 0.000e+00]\n",
      "  [2.180e+02 1.093e+03]]\n",
      "\n",
      " [[3.480e+02 6.250e+02]\n",
      "  [2.900e+01 3.090e+02]]\n",
      "\n",
      " [[0.000e+00 0.000e+00]\n",
      "  [2.110e+02 1.100e+03]]\n",
      "\n",
      " [[1.600e+01 9.800e+01]\n",
      "  [2.960e+02 9.010e+02]]\n",
      "\n",
      " [[0.000e+00 0.000e+00]\n",
      "  [2.320e+02 1.079e+03]]\n",
      "\n",
      " [[1.000e+00 3.300e+01]\n",
      "  [3.290e+02 9.480e+02]]]\n",
      "\n",
      "Evaluating kNN Regression...\n",
      "Cross validation with kNN Regression: 53.17%\n",
      "Accuracy using kNN Regression: 49.81%\n",
      "Confusion Matrix for kNN Regression:\n",
      "[[[ 191.   10.]\n",
      "  [ 131.  979.]]\n",
      "\n",
      " [[  71.    6.]\n",
      "  [ 142. 1092.]]\n",
      "\n",
      " [[ 162.    9.]\n",
      "  [ 135. 1005.]]\n",
      "\n",
      " [[  46.   10.]\n",
      "  [ 172. 1083.]]\n",
      "\n",
      " [[ 302.   36.]\n",
      "  [  75.  898.]]\n",
      "\n",
      " [[  56.    6.]\n",
      "  [ 155. 1094.]]\n",
      "\n",
      " [[ 202.   19.]\n",
      "  [ 110.  980.]]\n",
      "\n",
      " [[  58.   12.]\n",
      "  [ 174. 1067.]]\n",
      "\n",
      " [[ 208.   12.]\n",
      "  [ 122.  969.]]]\n",
      "\n",
      "MLP Below:\n",
      "Cross validation with MLP Regression: 58.84%\n",
      "Accuracy using MLP Regression: 51.79%\n",
      "Confusion Matrix for MLP Regression:\n",
      "[[[1.810e+02 4.000e+00]\n",
      "  [1.410e+02 9.850e+02]]\n",
      "\n",
      " [[9.000e+01 2.000e+00]\n",
      "  [1.230e+02 1.096e+03]]\n",
      "\n",
      " [[1.670e+02 1.000e+01]\n",
      "  [1.300e+02 1.004e+03]]\n",
      "\n",
      " [[6.000e+01 1.000e+00]\n",
      "  [1.580e+02 1.092e+03]]\n",
      "\n",
      " [[2.680e+02 1.800e+01]\n",
      "  [1.090e+02 9.160e+02]]\n",
      "\n",
      " [[6.600e+01 1.000e+00]\n",
      "  [1.450e+02 1.099e+03]]\n",
      "\n",
      " [[1.770e+02 5.000e+00]\n",
      "  [1.350e+02 9.940e+02]]\n",
      "\n",
      " [[7.100e+01 0.000e+00]\n",
      "  [1.610e+02 1.079e+03]]\n",
      "\n",
      " [[1.850e+02 5.000e+00]\n",
      "  [1.450e+02 9.760e+02]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#split the data with multiple labels based on format of data\n",
    "def multi_label_confusion_matrix(y_true, y_pred):\n",
    "    num_labels = y_true.shape[1]\n",
    "    #confusion matrix\n",
    "    conf_matrix = np.zeros((num_labels, 2, 2))\n",
    "    #combinations\n",
    "    for i in range(num_labels):\n",
    "        #check if values in certain rows result to true\n",
    "        tp = np.sum((y_true[:, i] == 1) & (y_pred[:, i] == 1))\n",
    "        tn = np.sum((y_true[:, i] == 0) & (y_pred[:, i] == 0))\n",
    "        fp = np.sum((y_true[:, i] == 0) & (y_pred[:, i] == 1))\n",
    "        fn = np.sum((y_true[:, i] == 1) & (y_pred[:, i] == 0))\n",
    "        conf_matrix[i] = [[tp, fp], [fn, tn]]\n",
    "    return conf_matrix\n",
    "data = np.loadtxt('datasets/tictac_multi.txt')\n",
    "X = data[:,:9]\n",
    "y = data[:,9:]\n",
    "#scale the data\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "#split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=23)\n",
    "#cross validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "print(\"Linear regression: \")\n",
    "linear_models = [LinearRegression() for _ in range(9)]\n",
    "#initialize arrays for splitting of data\n",
    "predictions = []\n",
    "cross_val_accuracies_lr = []\n",
    "#iterate each linear model for this type of regression and data and add to initialized arrays\n",
    "for i, model in enumerate(linear_models):\n",
    "    acc = cross_val_score(model, X, y[:, i], cv=kf)\n",
    "    cross_val_accuracies_lr.append(np.mean(acc))\n",
    "    model.fit(X_train, y_train[:, i])\n",
    "    pred = model.predict(X_test)\n",
    "    predictions.append(pred)\n",
    "#check the score of corss validation\n",
    "mean_cross_val_accuracy_lr = np.mean(cross_val_accuracies_lr)\n",
    "#cross validation code\n",
    "print(f\"cross validation with Linear Regression: {mean_cross_val_accuracy_lr * 100:.2f}%\")\n",
    "predictions = np.array(predictions).T\n",
    "#round or clamp to 0 or 1 for each regression output\n",
    "predictions = (predictions == predictions.max(axis=1)[:, None]).astype(int)\n",
    "acc = accuracy_score(y_test, predictions)\n",
    "#show accuracy with linear regression\n",
    "print(f\"Accuracy using Linear Regression: {acc * 100:.2f}%\")\n",
    "print(\"Confusion Matrix for Linear Regression:\")\n",
    "print(multi_label_confusion_matrix(y_test, predictions))\n",
    "# KNN regression below\n",
    "print(\"\\nEvaluating kNN Regression...\")\n",
    "#i chose to use 15 neighbors here\n",
    "knn = KNeighborsRegressor(n_neighbors=15)\n",
    "cross_val_accuracies_knn = cross_val_score(knn, X, y, cv=kf)\n",
    "mean_cross_val_accuracy_knn = np.mean(cross_val_accuracies_knn)\n",
    "#show cross validation score with using KNN\n",
    "print(f\"Cross validation with kNN Regression: {mean_cross_val_accuracy_knn * 100:.2f}%\")\n",
    "#train the data\n",
    "knn.fit(X_train, y_train)\n",
    "knn_preds = knn.predict(X_test)\n",
    "knn_preds = (knn_preds == knn_preds.max(axis=1)[:, None]).astype(int)\n",
    "#show the accuracy with the KNN model\n",
    "acc = accuracy_score(y_test, knn_preds)\n",
    "print(f\"Accuracy using kNN Regression: {acc * 100:.2f}%\")\n",
    "print(\"Confusion Matrix for kNN Regression:\")\n",
    "print(multi_label_confusion_matrix(y_test, knn_preds))\n",
    "# MLP Regression\n",
    "print()\n",
    "print(\"MLP Below:\")\n",
    "#use mlp and layer it with a random state as well\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(100,), max_iter=10000, random_state=23)\n",
    "#cross validate with mlp\n",
    "cross_val_accuracies_mlp = cross_val_score(mlp, X, y, cv=kf)\n",
    "mean_cross_val_accuracy_mlp = np.mean(cross_val_accuracies_mlp)\n",
    "#show the accuracy of cross validation with mlp\n",
    "print(f\"Cross validation with MLP Regression: {mean_cross_val_accuracy_mlp * 100:.2f}%\")\n",
    "#train the data\n",
    "mlp.fit(X_train, y_train)\n",
    "mlp_preds = mlp.predict(X_test)\n",
    "mlp_preds = (mlp_preds == mlp_preds.max(axis=1)[:, None]).astype(int)\n",
    "acc = accuracy_score(y_test, mlp_preds)\n",
    "#show the accuracy and confusion matrix\n",
    "print(f\"Accuracy using MLP Regression: {acc * 100:.2f}%\")\n",
    "print(\"Confusion Matrix for MLP Regression:\")\n",
    "print(multi_label_confusion_matrix(y_test, mlp_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7704c4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | | \n",
      " | | \n",
      " | | \n",
      "Your move (1-9): 9\n",
      " | | \n",
      " |O| \n",
      " | |X\n",
      "Your move (1-9): 1\n",
      "X| | \n",
      " |O|O\n",
      " | |X\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#currently trying tic tac toe against mlp regression\n",
    "# load and preprocess data\n",
    "data = np.loadtxt('datasets/tictac_multi.txt')\n",
    "X = data[:, :9]\n",
    "y = data[:, 9:]\n",
    "#scale the data\n",
    "scaler = StandardScaler().fit(X)\n",
    "#use mlp\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(100,), max_iter=10000).fit(scaler.transform(X), y)\n",
    "#define how the ML will make a move\n",
    "def ML_move(board):\n",
    "    #make prediction\n",
    "    preds = mlp.predict(scaler.transform([board]))\n",
    "    #make a move\n",
    "    move = np.argmax(preds)\n",
    "    #return the move value\n",
    "    while board[move] != 0:\n",
    "        preds[0][move] = -np.inf\n",
    "        move = np.argmax(preds)\n",
    "    return move\n",
    "#print the board\n",
    "def print_board(b):\n",
    "    chars = ['O', ' ', 'X']\n",
    "    for i in range(0, 9, 3):\n",
    "        #print for each row/col in the tic tac toe board\n",
    "        print(\"|\".join([chars[val+1] for val in b[i:i+3]]))\n",
    "#hardcoded to see which game state had a winner\n",
    "def check_winner(b):\n",
    "    wins = [(0,1,2), (3,4,5), (6,7,8), (0,3,6), (1,4,7), (2,5,8), (0,4,8), (2,4,6)]\n",
    "    #return the possibility of someone winning\n",
    "    return any(b[i] == b[j] == b[k] and b[i] != 0 for i, j, k in wins)\n",
    "#initalize the board\n",
    "board = np.zeros(9, dtype=int)\n",
    "#while true meaning we keep playing the game (didn't make it continuous)\n",
    "while True:\n",
    "    print_board(board)\n",
    "    move = int(input(\"Your move (1-9): \"))\n",
    "    move -=1\n",
    "    if board[move] == 0:\n",
    "        board[move] = 1\n",
    "        if check_winner(board):\n",
    "            print_board(board)\n",
    "            print(\"win\")\n",
    "            break\n",
    "        if 0 not in board:\n",
    "            print_board(board)\n",
    "            print(\"draw\")\n",
    "            break\n",
    "        board[ML_move(board)] = -1\n",
    "        if check_winner(board):\n",
    "            print_board(board)\n",
    "            print(\"loss\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73515e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extra Credit Linear Regression normal equations\n",
    "#https://www.educative.io/answers/a-deep-dive-into-linear-regression-3-way-implementation\n",
    "#I used the article above to try and learn more about it (not sure if i'm correct in this implementation)\n",
    "#I'm trying to use theta = (X^TX)^(-1)X^Ty\n",
    "import numpy as np\n",
    "#some X variable\n",
    "X = sudodata\n",
    "Y = sudodata\n",
    "\n",
    "#add bias\n",
    "xb = np.c_[np.ones((X.shape[0], 1)), X]\n",
    "    \n",
    "#theta??\n",
    "theta = np.linalg.pinv(xb.T.dot(xb)).dot(xb.T).dot(y) \n",
    "\n",
    "#theta would be the output?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188e90cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
